

## 2.3.0后段发布文档

### 1.备份

#### a.快照备份

#### b.数据库备份

```mysql
mysqldump \
--host=host \
--port=短口 \
--user=用户名 \
--password \
--compress \
--databases 数据库名 \
--set-charset \
--default-character-set=utf8mb4 \
--opt \
--no-create-db \
--column-statistics=0 \
--skip-lock-tables \
--set-gtid-purged=OFF \
> 备份的脚本名.sql
```



### 2.添加数据库字段

```mysql
-- 添加昵称首字母
ALTER table user_profile ADD COLUMN nickname_initial VARCHAR(4)  COMMENT '昵称首字母' AFTER `nickname`;

-- 添加has_stress_state
ALTER table `record` ADD COLUMN `has_stress_state` tinyint(4) NOT NULL DEFAULT '0'  COMMENT '是否是应激态' AFTER `s3_key`;

-- 添加stress_state
ALTER table `record` ADD COLUMN `stress_state` varchar(1000)  COMMENT 'json格式的应激态状态，格式map[string]bool' AFTER `has_stress_state`;

-- 添加analyze_body
ALTER table `record` ADD COLUMN `analyze_body` varchar(8000)  COMMENT '新分析接口的body' AFTER `stress_state`;
```

### 3.发布镜像

#### a.在配置过aws的本地，使用`aws ecr get-login --no-include-email --region cn-north-1` 获取docker的login语句，在2台服务器上分别登录docker

#### b.在2台机器的docker-compose 文件中添加一下代码

##### i.私有ip是10-0-1-60机器

每个服务都添加

```json
environment:
 - LOG_FORMAT=logstash
```
添加svc-analysis服务

```json
 # JM svc-analysis
  svc-analysis:
    image: 949191617935.dkr.ecr.cn-north-1.amazonaws.com.cn/jm-app/svc-analysis:2.3.0
    entrypoint:
      - "/svc-analysis_linux_amd64"
      - "--registry=consul"
      - "--registry_address=ip-10-0-1-60.cn-north-1.compute.internal"
			- "--server_address=:9690"
    environment:
      - LOG_FORMAT=logstash
    env_file:
      - ./local.svc-analysis.env
    network_mode: "host"
```

##### ii.私有ip是10-0-0-60机器

每个服务都添加
```json
environment:
 - LOG_FORMAT=logstash
```
添加svc-analysis服务
```json
 # JM svc-analysis
  svc-analysis:
    image: 949191617935.dkr.ecr.cn-north-1.amazonaws.com.cn/jm-app/svc-analysis:2.3.0
    entrypoint:
      - "/svc-analysis_linux_amd64"
      - "--registry=consul"
      - "--registry_address=ip-10-0-0-60.cn-north-1.compute.internal"
			- "--server_address=:9690"
    environment:
      - LOG_FORMAT=logstash
    env_file:
      - ./local.svc-analysis.env
    network_mode: "host"
```

#### c.更新2台机器的.env文件

##### i. 修改`local.svc-biz-core.env` 

```
X_JINMU_H5_SERVER_BASE_V2_1=https://h5.jinmuhealth.com/app_h5/v2_1
```

##### ii 添加`local.svc-analysis.env`

```json
X_DB_ADDRESS=jinmu-prod.cjzrjn31gtsw.rds.cn-north-1.amazonaws.com.cn:53306
X_DB_USERNAME=jmapp2
X_DB_PASSWORD=数据库密码
X_DB_DATABASE=jinmu
X_DB_ENABLE_LOG=false
X_DB_MAX_CONNECTIONS=1 
X_AWS_BUCKET_NAME=jm-measurement-data
X_AWS_ACCESS_KEY=X_AWS_ACCESS_KEY
X_AWS_SECRET_KEY=aws密钥
X_AWS_REGION=cn-north-1
X_WAVE_DATA_KEY_PREFIX=production
X_PULSE_TEST_RAW_DATA_S3_KEY_PREFIX=spec-v2

```

#### d.把report的分析报告放入2台机器

* 找web获取report的分析报告
* 在该文件夹跟目录执行 `scp -r -i ~g2-XXX.pem ./*  jm-admin@ip:~/gf-api2/wxh5/app_h5/v2_1/`

#### e.更新服务器

* 使用jenkins打包master分支的镜像，并推到aws的ECR仓库中
* 执行以下命令拉取并重启服务

```sh
sudo docker-compose pull 
sudo docker-compose down
sudo docker-compose up -d
sudo docker-compose ps -a
```

#### f.测试API

##### 1.用postman测试

##### 2.是接口用例测试

##### 3.app测试

### 4.迁移旧数据

#### a.迁移用户首字母

*  按照`ops-tools`项目中`insert_nickname_initial`文件夹的README.MD顺序执行
   *  先执行文件夹中的`1.sql`脚本，创建`temp_user_profile`临时表
   *  执行文件夹中的`insert_nickname_initial.go`脚本生成`nickname_initial`文件夹
   *  把生成的`nickname_initial` 文件夹和同目录的`run.sh`放入其中一台机器上，`scp -r -i ~g2-XXX.pem .nickname_initial/*  jm-admin@ip:~/`
   *  执行`./run.sh`,等待并查看执行日志，并确认生成的`nickname_initial`脚本被全部执行
   *  执行`ops-tools`项目中`insert_nickname_initial`文件夹中的`2.sql`脚本，把从临时表首字母迁移到正式表中

#### b.迁移旧AE记录
*  按照`ops-tools`项目中`convert_new_ae_body`文件夹的README.MD顺序执行
   *  先执行文件夹中的`1.sql`脚本，创建`temp_record`临时表
   *  执行文件夹中的`convert_new_ae_body.go`脚本生成`convert_new_ae_body`文件夹
   *  把生成的`convert_new_ae_body` 文件夹和同目录的`run.sh`放入其中一台机器上，`scp -r -i ~g2-XXX.pem .convert_new_ae_body/*  jm-admin@ip:~/`
   *  执行`./run.sh`,等待并查看执行日志，并确认生成的`convert_new_ae_body`脚本被全部执行
   *  执行`ops-tools`项目中`convert_new_ae_body`文件夹中的`2.sql`脚本，把从AE新增字段迁移到正式表中
