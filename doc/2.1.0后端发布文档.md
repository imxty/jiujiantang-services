## 2.1.0后端发布文档

### 迁移aws数据
  ```sh
aws s3 sync s3://jm-measurement-data/production/ s3://jm-measurement-data/production/spec-v1/ --include "*.txt" --exclude "spec-v1"  
  ```

### 数据库备份(重点)

* dump数据库到本地

* 数据库快照

### 修改不影响线上的数据脚本

```mysql
-- 修改原先subscription_transfer_record错误的COMMENT
ALTER  TABLE `subscription_transfer_record` COMMENT '订阅转让记录表';
-- 修改枚举类型
ALTER  TABLE `user_profile` MODIFY COLUMN `gender` varchar(10) COMMENT '用户性别 M 男 F 女';
ALTER  TABLE `local_notifications` MODIFY COLUMN `frequency` varchar(30) COMMENT '推送时间间隔基本单位,FrequencyDaily,FrequencyWeekly,FrequencyMonthly';
ALTER  TABLE `audit_user_credential_update` MODIFY COLUMN `updated_record_type` varchar(20) COMMENT '更新记录的类型,username,phone,email,password';
ALTER  TABLE `audit_user_signin_signout` MODIFY COLUMN `record_type` varchar(10) NOT NULL COMMENT '登录或登出记录的类型,signin,signout';
ALTER  TABLE `verification_code` MODIFY COLUMN `send_via` varchar(10) NOT NULL  COMMENT '发送方式,phone,email';
-- 修改user_id类型
ALTER  TABLE `audit_user_signin_signout` MODIFY COLUMN `user_id` INT(10) UNSIGNED COMMENT '用户ID';
ALTER  TABLE `user_profile` MODIFY COLUMN `user_id` INT(10) UNSIGNED COMMENT '用户ID';
ALTER  TABLE `phone_or_email_verfication` MODIFY COLUMN `user_id` INT(10) UNSIGNED COMMENT '用户ID';
ALTER  TABLE `pn_record` MODIFY COLUMN `user_id` INT(10) UNSIGNED COMMENT '用户ID';
--  删除2个索引
ALTER TABLE `sem_record` DROP  KEY `idx_to_address`;
ALTER TABLE `sms_record` DROP  KEY `idx_phone`;
-- 添加索引
ALTER TABLE `user_access_token` ADD  KEY `idx_expired_at` (`expired_at`) USING BTREE;
ALTER TABLE `verification_code` 
ADD  KEY `idx_sn` (`sn`) USING BTREE,
ADD  KEY `idx_code` (`code`) USING BTREE,
ADD  KEY `idx_send_to` (`send_to`) USING BTREE;
ALTER TABLE `wechat_user` ADD  KEY `idx_user_id` (`user_id`) USING BTREE;
--  废弃一个表
ALTER TABLE `organization_admin` RENAME `legacy_organization_admin`;

-- 修改phone_or_email_verfication的枚举类型
ALTER  TABLE `phone_or_email_verfication` MODIFY COLUMN `verification_type` varchar(10) NOT NULL  COMMENT '发送方式,phone,email';
-- 删除sms_record多余字段
ALTER  TABLE `sms_record` DROP COLUMN `expired_at`;
ALTER  TABLE `sms_record` DROP COLUMN `is_valid`;
-- 增加默认值
ALTER  TABLE `feedback` ALTER COLUMN `content` SET default '';
ALTER  TABLE `local_notifications` ALTER COLUMN `has_weekdays` SET default 0;
ALTER  TABLE `local_notifications` ALTER COLUMN `has_month_days` SET default 0;
-- 限制字段不可为空
ALTER TABLE `phone_or_email_verfication` MODIFY  `expired_at` datetime NOT NULL COMMENT '到期时间';
ALTER TABLE `subscription_transfer_record` MODIFY  `subscription_id` int(10) unsigned NOT NULL COMMENT '订阅ID';
ALTER TABLE `subscription_transfer_record` MODIFY  `user_id` int(10) unsigned NOT NULL COMMENT '用户ID';
ALTER TABLE `subscription_transfer_record` MODIFY  `old_user_id` int(10) unsigned NOT NULL COMMENT '原用户ID';
ALTER TABLE `verification_code` MODIFY  `expired_at` datetime NOT NULL COMMENT '到期时间';
ALTER TABLE `wechat_user` MODIFY  `user_id` int(10) unsigned NOT NULL COMMENT '喜马把脉用户ID';
```


### 发布代码到仓库

* 使用Jenkins把代码发布到仓库，tag 是2.1.0

### 修改配置文件

* 修改`docker-compose.yml`文件，把原来的`2.0.9`换成`2.1.0`
* 修改`local.svc-biz-core.env`文件，新加一行 `X_PULSE_TEST_RAW_DATA_S3_KEY_PREFIX=spec-v2`

### 停机

* 登录2台正式环境的机器

* 运行`sudo docker-compose down`

### 修改线上的数据库数据

* 执行数据库脚本

  ```mysql
  SET NAMES utf8mb4;
  SET FOREIGN_KEY_CHECKS = 0;
  
  -- 添加s3-key
  ALTER table `record` ADD COLUMN `s3_key` VARCHAR(50)  COMMENT 's3的key' AFTER `transaction_number`;
  -- 迁移老的数据
  UPDATE `record` as R set `s3_key` = concat('spec-v1/',R.record_id,'.txt') where R.record_id >= '100000';
  ```


### 发布

* 拉取镜像 `sudo docker-compose pull`
* 启动镜像 `sudo docker-compose up -d`
* 查看镜像运行情况 `sudo docker ps -a`

### 验证

* 后端可以使用postman进行验证

  * API 测量接口，分析接口
  * 数据 老的数据`.txt`,新的数据`.pbd`

* 测试可以使用app进行验证

  * 功能测试 使用app内部历史记录的模块

  * API接口测试 可以使用API接口测试代码跑测量接口，分析接口
  
### 移除aws上的数据到一个文件夹

```sh
aws s3 sync s3://jm-measurement-data/production/ s3://jm-measurement-data/production/spec-v1/ --include "*.txt" --exclude "spec-v1"  
aws s3 mv s3://jm-measurement-data/production/ s3://jm-measurement-data/production/discard/ --include "*.txt" --exclude "discard"  --recursive
```

### 数据没有问题后干掉aws上的`discard`文件夹
